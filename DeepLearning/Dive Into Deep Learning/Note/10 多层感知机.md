
# 感知机

- 给定输入 $x$ ,权重，偏移，感知机输出
- 二分类：-1或者1
	- Vs.softmax
	- Vs.线性回归
- 训练感知机 （林轩田）
	- 等价于使用批量大小为1的梯度下降
- 收敛定理
	- 数据在半径r内
	- 余量
	- 保证收敛
	- 线性可分
- $XOR$ 问题
	- 感知机不能拟合 $XOR$ 问题，只能产生线性分割面


- 感知机是一个二分类模型，是最早的AI模型之一
- 它的求解算法等价于使用批量大小为1的梯度下降
- 不能拟合XOR，导致了第一次AI寒冬

# 多次感知机

- 学习$XOR$
- 单隐藏层
	- Input layer
	- Hidden layer
		- 大小是一个超参数
	- Output layer
	- 单分类
- 激活函数
	- 为什么需要非线性的激活函数
		- 算出来的还是线性模型
	- Sigmoid激活函数
		- 将输入投影到$(0,1)$,是一个软的 soft的
	- Tanh激活函数
		- 将输入投影到$(-1,1)$
	- ReLU激活函数
		- ReLU: rectified linear unit
		- 算起来很快，不用做指数运算
- 多类分类
	- $softmax(o_1,o_2,\dots,o_k)$
- 多隐藏层
	- 超参数
		- 隐藏层数
		- 每层隐藏层的大小
		- 输入数据比较难
			- 单隐藏层m比较大
			- 模型变深，m1小一点，m2小一点，m3更小

# 代码实现

